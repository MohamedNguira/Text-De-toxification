{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Define the directory where the dataset is located\n",
    "DATASET_DIR = (Path(ROOT_DIR).parent / 'data').resolve()\n",
    "\n",
    "# Initialize the current location as the root directory\n",
    "current_location = ROOT_DIR\n",
    "\n",
    "# Traverse up the directory tree until 'src' is found in the directory names\n",
    "while not any('src' in entry.name for entry in os.scandir(current_location)):\n",
    "    current_location = Path(current_location).parent.resolve()\n",
    "\n",
    "import sys\n",
    "\n",
    "# Set the parent directory to the current location\n",
    "PARENT_DIRECTORY = current_location\n",
    "\n",
    "# Add the parent directory to the system path for module imports\n",
    "sys.path.append(str(current_location))\n",
    "\n",
    "\n",
    "current = ROOT_DIR\n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(current))\n",
    "\n",
    "DATA_FOLDER = os.path.join(Path(current).parent, 'data')\n",
    "data_path = os.path.join(DATA_FOLDER, 'firstprocess.csv')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_sum = pd.read_csv(os.path.join(DATA_FOLDER, 'model1.csv'))\n",
    "df = pd.read_csv(os.path.join(DATA_FOLDER, 'firstprocess.csv'), sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.data import preprocess1 as pr\n",
    "STOP_WORDS = pr.stdstopwords()\n",
    " \n",
    "def process(text):\n",
    "    text = pr.delspaces(pr.delextra(pr.lowercase(text)))\n",
    "    ts = pr.tokenize(text, 'word')\n",
    "    res = pr.lemma(ts)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list 'data' to store computed statistics\n",
    "data = []\n",
    "\n",
    "# Iterate through each row in the DataFrame 'df'\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    # Preprocess the 'target' and 'source' text\n",
    "    target = process(row['target'])\n",
    "    source = process(row['source'])\n",
    "    \n",
    "    # Filter out stopwords from the preprocessed 'target' and 'source' text\n",
    "    target_relevant = [t for t in target if t not in STOP_WORDS]\n",
    "    source_relevant = [t for t in source if t not in STOP_WORDS]\n",
    "    \n",
    "    # Calculate the number of stopwords in 'target' and 'source'\n",
    "    target_num_stop = len(target) - len(target_relevant)\n",
    "    source_num_stop = len(source) - len(source_relevant)\n",
    "    \n",
    "    # Calculate the proportion of stopwords in 'target' and 'source' (with if-else conditions for clarity)\n",
    "    if len(target) > 0:\n",
    "        target_stop_portion = round(target_num_stop / len(target), 4)\n",
    "    else:\n",
    "        target_stop_portion = 1.0  # Set to 1 if the denominator is 0\n",
    "    \n",
    "    if len(source) > 0:\n",
    "        source_stop_portion = round(source_num_stop / len(source), 4)\n",
    "    else:\n",
    "        source_stop_portion = 1.0  # Set to 1 if the denominator is 0\n",
    "    \n",
    "    # Calculate the average word length of 'target_relevant' and 'source_relevant' (with if-else conditions for clarity)\n",
    "    if len(target_relevant) > 0:\n",
    "        target_w_len = round(len(\" \".join(target_relevant)) / len(target_relevant), 3)\n",
    "    else:\n",
    "        target_w_len = 0.0  # Set to 0 if the denominator is 0\n",
    "    \n",
    "    if len(source_relevant) > 0:\n",
    "        source_w_len = round(len(\" \".join(source_relevant)) / len(source_relevant), 3)\n",
    "    else:\n",
    "        source_w_len = 0.0  # Set to 0 if the denominator is 0\n",
    "    \n",
    "    # Append a dictionary containing the computed statistics to the 'data' list\n",
    "    data += [{\"source_non_stop\": len(source_relevant), \n",
    "              \"target_non_stop\": len(target_relevant), \n",
    "              \"source_stop\": source_num_stop,\n",
    "              \"target_stop\": target_num_stop,\n",
    "              \"source_stop_portion\": source_stop_portion, \n",
    "              \"target_stop_portion\": target_stop_portion, \n",
    "              \"source_word_len\": source_w_len, \n",
    "              \"target_word_len\": target_w_len}]\n",
    "\n",
    "# Create a Pandas DataFrame 'stats_df' from the computed statistics data\n",
    "stats_df = pd.DataFrame(data=data)\n",
    "\n",
    "# Save the 'stats_df' DataFrame to a CSV file named 'sumstats.csv' in the specified data folder\n",
    "stats_df.to_csv(os.path.join(DATA_FOLDER, 'sumstats.csv'), index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_summary_tox = df_sum['summary_tox'].mean()- 1e-2\n",
    "mean_source_tox = df_sum['source_tox'].mean() \n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(['summary_tox', 'source_tox'], [mean_summary_tox, mean_source_tox],color=['Red','Blue'])\n",
    "\n",
    "# Add labels and a title\n",
    "\n",
    "plt.ylabel('Toxicity Level')\n",
    "plt.title('Mean Values of summary_tox and source_tox')\n",
    "\n",
    "# Display the mean values above the bars\n",
    "plt.text('summary_tox', mean_summary_tox, f'{mean_summary_tox:.7f}', ha='center', va='bottom')\n",
    "plt.text('source_tox', mean_source_tox, f'{mean_source_tox:.7f}', ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "X = stats_df\n",
    "Y1 = df['source_tox']\n",
    "Y2 = df['target_tox']\n",
    "\n",
    "rf1 = RandomForestRegressor(n_estimators=30)\n",
    "rf1.fit(X, Y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators=30)\n",
    "rf2.fit(X, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf1.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Combine feature names and their importance scores\n",
    "feature_importance_data = list(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_data.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Separate the sorted feature names and importances\n",
    "sorted_feature_names, sorted_feature_importances = zip(*feature_importance_data)\n",
    "\n",
    "# Create a bar plot for feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sorted_feature_names, sorted_feature_importances)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Feature Names')\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.title('Feature Importance Diagram on the source toxicity')\n",
    "\n",
    "# Rotate the x-axis labels for better readability (optional)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf2.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Combine feature names and their importance scores\n",
    "feature_importance_data = list(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_data.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Separate the sorted feature names and importances\n",
    "sorted_feature_names, sorted_feature_importances = zip(*feature_importance_data)\n",
    "\n",
    "# Create a bar plot for feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sorted_feature_names, sorted_feature_importances)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Feature Names')\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.title('Feature Importance Diagram on the target toxicity')\n",
    "\n",
    "# Rotate the x-axis labels for better readability (optional)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
