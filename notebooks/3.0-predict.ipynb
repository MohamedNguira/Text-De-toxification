{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the required checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import gdown\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def download_checkpoints():\n",
    "    HOME = os.getcwd()\n",
    "    current = HOME \n",
    "    while 'src' not in os.listdir(current):\n",
    "        current = Path(current).parent\n",
    "    checkpoint_dir = str(current) + '\\\\checkpoints'\n",
    "    url =\"https://drive.google.com/file/d/1OzdC7oYtZoQlIEWYPz0Z0OBvzGNMwiTB/view?usp=sharing\"\n",
    "    gdown.download(url, checkpoint_dir + '\\\\checkpoints.zip', quiet=False, fuzzy=True, use_cookies=False)\n",
    "    with zipfile.ZipFile(checkpoint_dir + '\\\\checkpoints.zip', 'r') as zip_ref:\n",
    "      zip_ref.extractall(checkpoint_dir)\n",
    "    os.remove(checkpoint_dir + '\\\\checkpoints.zip')\n",
    "\n",
    "download_checkpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Output using the data/test.csv file\n",
    "If you want to create your own test data set just replace this file with your own test.csv file following the same format.\n",
    "Results will be shown in results.txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification\\\\notebooks', 'c:\\\\Users\\\\m4mou\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip', 'c:\\\\Users\\\\m4mou\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs', 'c:\\\\Users\\\\m4mou\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib', 'c:\\\\Users\\\\m4mou\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', '', 'C:\\\\Users\\\\m4mou\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\m4mou\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\m4mou\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\m4mou\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\m4mou\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification\\\\data_analysis', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification\\\\evaluation', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification\\\\text_processing', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification', 'c:\\\\Users\\\\m4mou\\\\Desktop\\\\pmldl\\\\mywork\\\\Text-De-toxification']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041a1540f70645cdb35c1b07db8ab91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb985c4555244ce786c6cb3dc652e742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a42936ac9441acac78187237539bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de20adc21e8743c6bb3eb6c629cb60c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "HOME = os.getcwd()\n",
    "\n",
    "current = HOME \n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "PARENT_DIR = str(current)\n",
    "DATA_FOLDER = os.path.join(PARENT_DIR,'data')\n",
    "data_path = os.path.join(DATA_FOLDER, 'filtered.tsv')\n",
    "\n",
    "sys.path.append(str(current))\n",
    "print(sys.path)\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src.models.predict.s2sposttrain import prepare_sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict():\n",
    "    checkpoint = 'facebook/bart-base'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    seq2seq_checkpoint = os.path.join(PARENT_DIR, \n",
    "                                      'checkpoints', \n",
    "                                      's2s', \n",
    "                                      'seq2seq_checkpoints', \n",
    "                                      'checkpoint-21200')\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(seq2seq_checkpoint).to('cuda')\n",
    "\n",
    "    test_data = load_dataset(\"csv\", data_files=os.path.join(DATA_FOLDER, 'test.csv'), split='train')\n",
    "    test_data = test_data.map(lambda b: prepare_sample(b, tokenizer=tokenizer), batched=True).remove_columns(['source', 'target'])\n",
    "\n",
    "    with open(os.path.join(current, \"results.txt\"), 'w') as file:\n",
    "        for i in range(len(test_data)):\n",
    "            input_ids = test_data[i]['input_ids']\n",
    "            attention_mask = test_data[i]['attention_mask']\n",
    "\n",
    "            outputs = model.generate(\n",
    "                input_ids=torch.tensor(input_ids).unsqueeze(0).to('cuda'),\n",
    "                attention_mask=torch.tensor(attention_mask).unsqueeze(0).to('cuda'),\n",
    "                max_length=512,\n",
    "                num_beams=2,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            file.write(f'{generated}\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
